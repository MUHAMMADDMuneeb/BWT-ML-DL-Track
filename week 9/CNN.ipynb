{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Understanding CNNs<br>\n",
    "Study the provided resources to understand the basic concepts of CNNs, convolutional layers, and pooling layers, and answer the following questions.<br><br>\n",
    "   - What are the advantages of convolutional layers over fully connected layers in image processing tasks?<br>\n",
    "   Answer:<br>   By scanning the image with a sliding window, convolutional layers can detect features regardless of their position in    the image, providing a degree of translation invariance.<br>\n",
    "   Convolutional layers can capture spatial hierarchies in images by preserving the spatial relationship between pixels. They are designed to recognize patterns such as edges, textures, and shapes, which are crucial for understanding image content.<br>\n",
    "   Convolutional layers share weights across the input image (via the convolution operation), significantly reducing the number of parameters compared to fully connected layers. This makes convolutional neural networks (CNNs) less prone to overfitting and more memory-efficient.<br><br>\n",
    "\n",
    "   - How does pooling help in reducing the computational complexity of a CNN?<br>\n",
    "   Answer:<br>\n",
    "   Reduction in Computational Complexity: By reducing the spatial size of the feature maps, pooling layers decrease the number of parameters and computations in subsequent layers, making the network more efficient.<br>\n",
    "   Control Overfitting: Pooling helps to reduce the size of the feature maps, which in turn reduces the capacity of the network, helping to control overfitting.<br><br>\n",
    "\n",
    "\n",
    "   - Compare different types of pooling layers (max pooling, average pooling). What are their respective advantages and disadvantages?<br>\n",
    "   Max Pooling:-<br>\n",
    "   Mechanism: Max pooling selects the maximum value from each patch of the feature map.<br>\n",
    "   Advantages:<br>\n",
    "   Feature Detection: It emphasizes the most prominent features, such as edges, by retaining the strongest activations.<br>\n",
    "   Non-linearity: Introduces non-linearity into the model, helping in learning more complex patterns.<br>\n",
    "   Average Pooling:-<br>\n",
    "   Mechanism: Average pooling computes the average of all values in the patch of the feature map.<br>\n",
    "   Advantages:<br>\n",
    "   Smooth Features: Provides a smoother representation of the features, which can be useful for tasks requiring general feature representations.<br>\n",
    "   Less Sensitivity to Noise: By averaging, it reduces the influence of noise and outliers.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Implementing a CNN<br>\n",
    "MNIST<br>\n",
    "1. Build a Simple CNN on the MNIST Dataset:<br>\n",
    "   - Create a simple CNN architecture on the MNIST dataset and document what difference have you seen in results compared to your previous assignment where you had to develop a simple ANN model on the MNIST dataset.<br>\n",
    "   - Document the architecture of your CNN, including the number of layers, types of layers, and parameters used.<br>\n",
    "   - Train your CNN on the MNIST dataset and explore the use of callbacks (e.g., EarlyStopping, ModelCheckpoint) while training models.<br>\n",
    "   - Document the training process, including data preprocessing steps, training parameters (learning rate, batch size, epochs), and any challenges faced.<br>\n",
    "   - Evaluate the performance  <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8982 - loss: 0.3221 - val_accuracy: 0.9816 - val_loss: 0.0559\n",
      "Epoch 2/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9847 - loss: 0.0488 - val_accuracy: 0.9862 - val_loss: 0.0461\n",
      "Epoch 3/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - accuracy: 0.9901 - loss: 0.0310 - val_accuracy: 0.9861 - val_loss: 0.0473\n",
      "Epoch 4/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - accuracy: 0.9937 - loss: 0.0194 - val_accuracy: 0.9891 - val_loss: 0.0353\n",
      "Epoch 5/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - accuracy: 0.9944 - loss: 0.0165 - val_accuracy: 0.9877 - val_loss: 0.0449\n",
      "Epoch 6/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.9908 - val_loss: 0.0374\n",
      "Epoch 7/20\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.9898 - val_loss: 0.0451\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0479\n",
      "Test accuracy: 0.9898\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0352\n",
      "Best model test accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Reshape images to (28, 28, 1) for the CNN\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Load the best model (optional)\n",
    "best_model = models.load_model('best_model.keras')\n",
    "\n",
    "# Evaluate the best model on the test set (optional)\n",
    "best_test_loss, best_test_acc = best_model.evaluate(test_images, test_labels)\n",
    "print(f\"Best model test accuracy: {best_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build a Simple CNN for a Binary Classification Task:<br>\n",
    "   - Create a simple CNN architecture on the Cat-vs-Dog dataset and document<br>   \n",
    "   - Document the architecture of your CNN, including the number of layers, types of layers, and parameters used.<br>\n",
    "   - Train your CNN on the Cat-vs-Dog dataset and explore the use of callbacks (e.g., EarlyStopping, ModelCheckpoint) while training models.<br>\n",
    "   - Document the training process, including data preprocessing steps, training parameters (learning rate, batch size, epochs), and any challenges faced.<br>\n",
    "   - Evaluate the performance<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awais\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4998 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awais\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m914s\u001b[0m 1s/step - accuracy: 0.5370 - loss: 0.7306 - val_accuracy: 0.6070 - val_loss: 0.6598\n",
      "Epoch 2/6\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1102s\u001b[0m 2s/step - accuracy: 0.6373 - loss: 0.6415 - val_accuracy: 0.6853 - val_loss: 0.5954\n",
      "Epoch 3/6\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1356s\u001b[0m 2s/step - accuracy: 0.7006 - loss: 0.5754 - val_accuracy: 0.7109 - val_loss: 0.5514\n",
      "Epoch 4/6\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 1s/step - accuracy: 0.7313 - loss: 0.5345 - val_accuracy: 0.7501 - val_loss: 0.5104\n",
      "Epoch 5/6\n",
      "\u001b[1m403/625\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5:58\u001b[0m 2s/step - accuracy: 0.7390 - loss: 0.5238"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the path to the dataset\n",
    "data_dir = 'F:\\\\Bitwise ML DL Intership\\\\week 9\\\\Cat vs Dog\\\\PetImages'\n",
    "\n",
    "# Function to check if an image can be opened\n",
    "def is_image_valid(filepath):\n",
    "    try:\n",
    "        img = Image.open(filepath)\n",
    "        img.verify()  # Verify that it is, in fact, an image\n",
    "        return True\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f\"Invalid file: {filepath}\")\n",
    "        return False\n",
    "\n",
    "# Remove bad files from the dataset\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        if not is_image_valid(filepath):\n",
    "            os.remove(filepath)\n",
    "\n",
    "# Image data generators with augmentation for training and validation split\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest',\n",
    "                                   validation_split=0.2)  # 20% of data for validation\n",
    "\n",
    "# Loading data with the generators\n",
    "train_generator = train_datagen.flow_from_directory(data_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary',\n",
    "                                                    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(data_dir,\n",
    "                                                         target_size=(150, 150),\n",
    "                                                         batch_size=32,\n",
    "                                                         class_mode='binary',\n",
    "                                                         subset='validation')\n",
    "\n",
    "# Build the CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=6,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Load the best model (optional)\n",
    "best_model = models.load_model('best_model.keras')\n",
    "\n",
    "# Evaluate the best model on the validation set (optional)\n",
    "best_val_loss, best_val_acc = best_model.evaluate(validation_generator)\n",
    "print(f\"Best model validation accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is taking to much time i try to Trian it 2 times. At my first atempt i apply 20 Epoches and it take 120m annd it has done 9 Epoch and my laptop turn off although i have Apply the charger to it and on the Second attempt i Applied 6 Epoches and after 80 m it is in 5 epoch and shut down automatically. My Laptop did not do it before and it is taking to much time because the dataset is Colored image and it take 3 Metrics RGB. Thats why I am uploading it as it is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
